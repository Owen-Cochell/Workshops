{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ785a7Wycmv"
      },
      "source": [
        "# [Click here for workshop instructions](https://msu-ai.notion.site/Workshop-Instructions-71ae82f6d8d9452586e6626ffb48e1b9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PA59a8fQnTg"
      },
      "source": [
        "# Step 1: Download some images\n",
        "Before we can do any image manipulation, we need to download some images. Run the following commands to download some:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2--io2SlQ_TG"
      },
      "outputs": [],
      "source": [
        "!curl -o seagull.jpeg 'https://images.unsplash.com/photo-1451909496057-8c1b9c9fd247?w=1920' \\\n",
        "      -o polarbear.jpeg 'https://images.unsplash.com/photo-1589656966895-2f33e7653819?w=1920' \\\n",
        "      -o dog.jpeg 'https://images.unsplash.com/photo-1530281700549-e82e7bf110d6?w=1920' \\\n",
        "      -o cat.jpeg 'https://images.unsplash.com/photo-1495360010541-f48722b34f7d?w=1920' \\\n",
        "      -o sunflower.jpeg 'https://images.unsplash.com/photo-1470509037663-253afd7f0f51?w=1920' \\\n",
        "      -o pineapple.jpeg 'https://images.unsplash.com/photo-1550258987-190a2d41a8ba?w=1920' \\\n",
        "      -o donuts.jpeg 'https://images.unsplash.com/photo-1551024601-bec78aea704b?w=1920' \\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiA6PuqqQ4ul"
      },
      "source": [
        "Now that the images are downloaded, they should appear in the \"files\" panel on the left. And you'll be able to access them from your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQzYE6mbQaoD"
      },
      "source": [
        "# Step 2: Load an image\n",
        "Now that we have our images, let's try loading them in code. Edit the following so that it loads one of the images we just downloaded:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A04o4Cj-Utdp"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cv2'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/home/owen/Documents/projects/Workshops/opencv-intro/OpenCV_Workshop.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/owen/Documents/projects/Workshops/opencv-intro/OpenCV_Workshop.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m \u001b[39m# This is OpenCV\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/owen/Documents/projects/Workshops/opencv-intro/OpenCV_Workshop.ipynb#ch0000005?line=2'>3</a>\u001b[0m my_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39m### CHOOSE A FILE NAME TO GO HERE ###\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/owen/Documents/projects/Workshops/opencv-intro/OpenCV_Workshop.ipynb#ch0000005?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(my_image\u001b[39m.\u001b[39mshape)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
          ]
        }
      ],
      "source": [
        "import cv2 # This is OpenCV\n",
        "\n",
        "my_image = cv2.imread(\"### CHOOSE A FILE NAME TO GO HERE ###\")\n",
        "\n",
        "print(my_image.shape) # This should print out the height and width of the image, and the number 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyfabdHqWIXS"
      },
      "source": [
        "Hopefully you see the height and width of the image printed, along with the number 3.\n",
        "\n",
        "Why the number 3? The `.shape` of the image tells you how the data is stored. ([Learn more](https://msu-ai.notion.site/Workshop-Instructions-71ae82f6d8d9452586e6626ffb48e1b9#1783b3c3fa414ae2bbb05213722de75b)) In particular, the first number tells you how many rows of pixels there are (the height), the second number tells you how many pixels there are per row (the width), and the last number tells you how many channels there are per pixel. In this case it's 3 for R, G, and B. (Actually, though, OpenCV uses BGR -- it's still red, green, and blue, but they are sorted in reverse order. [Learn more](https://msu-ai.notion.site/Workshop-Instructions-71ae82f6d8d9452586e6626ffb48e1b9#0c004600ca9649fd8990b9664df280ee))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nng68PhPRuT"
      },
      "source": [
        "# Step 3: Display an image\n",
        "Now that you have an image loaded into `my_image`, let's try to display it on the screen. There are many ways to do this, but we will be using a library called matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52uH6P3wPQzL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(my_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oaYuc8SP5ST"
      },
      "source": [
        "**Uh oh!** The image's colors are all wrong! This is because OpenCV stores colors in BGR format, but matplotlib expects RGB format. The wires are getting crossed. To fix it, add `my_image = cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)` to the code above, which converts the BGR image to RGB form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvleXfy8RfM5"
      },
      "source": [
        "# Step 4: Display multiple images\n",
        "Once we start editing and manipulating images, we'll want to display side-by-side comparisons of multiple photos.\n",
        "\n",
        "matplotlib can do this, but the code isn't very concise. To make things easier, I've created a `show` function below that you can use to show as many images as you'd like, side-by-side. After you run this cell, the `show` function will always be available to you! We'll use it a lot later.\n",
        "\n",
        "Give it a run and see how it looks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYv9ulTsAIrE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Define the \"show\" function that displays multiple images\n",
        "def show(*images):\n",
        "  rows = 1\n",
        "  cols = len(images)\n",
        "\n",
        "  plt.figure(figsize=(16, 6 * rows))\n",
        "\n",
        "  for (i, image) in enumerate(images):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(image)\n",
        "\n",
        "# Test out the show function with three images:\n",
        "show(\n",
        "  cv2.imread(\"cat.jpeg\"),\n",
        "  cv2.imread(\"dog.jpeg\"),\n",
        "  cv2.imread(\"polarbear.jpeg\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtLMUqfldn1b"
      },
      "source": [
        "You should see a cat, a dog, and a polar bear all aligned in a row."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNuaxr0Odw4T"
      },
      "source": [
        "# Step 5: Invert an image\n",
        "Now that we have our `show` function handy, we can manipulate images and then view the result.\n",
        "\n",
        "Let's try using the `bitwise_not` operation to invert the colors of an image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gchALDbZd6aN"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "image = cv2.imread(\"### YOUR FAVORITE IMAGE FILE ###\")\n",
        "inverted = cv2.bitwise_not(image)\n",
        "\n",
        "show(image, inverted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2cuxCWeRvu"
      },
      "source": [
        "The `bitwise_not` operation works by inverting each B, G, and R value for each pixel. ([Learn more](https://msu-ai.notion.site/Workshop-Instructions-71ae82f6d8d9452586e6626ffb48e1b9#f9868ffb71264c9c824008098baaac79))\n",
        "\n",
        "This is a simple example of the kind of image filtering we can do with OpenCV. As we gain more and more tools, you'll be able to combine them in interesting ways!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97d5dftJe__3"
      },
      "source": [
        "# Step 6: Draw circles and rectangles\n",
        "We can also draw our own image with OpenCV. First let's create a 500x500 pixel image that is pure black:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGtUFHjIfSSM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Rather than loading an image from a file, we will\n",
        "# create the image data ourselves. It will be 500x500,\n",
        "# with 3 channels for the BGR values. Every single value\n",
        "# in the image will be 0, resulting in an all-black image.\n",
        "image = np.zeros((500, 500, 3), dtype=np.uint8)\n",
        "\n",
        "show(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsd665fDg-bh"
      },
      "source": [
        "OpenCV comes with many drawing functions, like `cv2.circle()`, `cv2.rectangle()`, and more. So let's try some drawing!\n",
        "\n",
        "**Modify the following code to draw your dream house.** (Don't leave your house floating in the void, either! I want to see a background too.)\n",
        "\n",
        "You'll need to use [the documentation for the drawing functions](https://docs.opencv.org/4.x/dc/da5/tutorial_py_drawing_functions.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBIfGPP1g8sX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "image = np.zeros((500, 500, 3), dtype=np.uint8)\n",
        "\n",
        "# Read the documentation here to learn how to draw your own house:\n",
        "# https://docs.opencv.org/4.x/dc/da5/tutorial_py_drawing_functions.html\n",
        "\n",
        "cv2.circle() # Fill this in!\n",
        "cv2.rectangle() # Fill this in!\n",
        "\n",
        "show(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_niTUaFixsY"
      },
      "source": [
        "# Step 7: Other bitwise operations\n",
        "Earlier we used `bitwise_not` to invert an image. But there are also other bitwise operations that combine two images together.\n",
        "\n",
        "Modify the following code to show `bitwise_or`, `bitwise_and`, and `bitwise_xor`. ([Learn more](https://msu-ai.notion.site/Workshop-Instructions-71ae82f6d8d9452586e6626ffb48e1b9#96220128d16c40d48299c66560f0ad16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmJX4ipwjmd-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Prepare image1 (sunflower)\n",
        "image1 = cv2.imread(\"sunflower.jpeg\")\n",
        "\n",
        "# Prepare image2 (drawn circle)\n",
        "image2 = np.zeros(image1.shape, dtype=np.uint8) # Use image1.shape to make sure both images are the same size\n",
        "cv2.circle(image2, center=(900, 1000), radius=600, color=(255, 255, 255), thickness=-1)\n",
        "\n",
        "# Combine using a bitwise operation\n",
        "combined = cv2.bitwise_and(image1, image2)\n",
        "\n",
        "# Display all three\n",
        "show(image1, image2, combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jVUnpw8kwpG"
      },
      "source": [
        "**Question:** What happens when you combine the images using `bitwise_and`? What about `bitwise_xor`?\n",
        "\n",
        "**Question:** How do the bitwise operations behave when you make the circle red?\n",
        "\n",
        "**Challenge question:** Do these results make sense when you think about the binary numbers that represent black vs white? What bout the binary numbers representing other colors, like red?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x1zsnLM5Au9"
      },
      "source": [
        "# Step 8: Blur an image\n",
        "Sometimes you might want to blur an image. In the context of machine learning, this is sometimes called \"smoothing\". It can be a useful way to remove noise and imperfections in an image. But for right now, we're just experimenting with blurring as a cool artistic effect.\n",
        "\n",
        "Your job is to head to Google and search for the OpenCV documentation on blurring an image. Can you manage to blur the parrot below?\n",
        "\n",
        "Once you've done that, try to change your code in the following ways:\n",
        "- Make the blur bigger\n",
        "- Make the blur horizontal only\n",
        "- Make the blur vertical only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unIiwxdJ5U50"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Your job: Blur the seagull\n",
        "\n",
        "seagull = cv2.imread(\"seagull.jpeg\")\n",
        "blurred = cv2.blur(seagull, (500,500))\n",
        "\n",
        "show(seagull, blurred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgE_wR8u6bgx"
      },
      "source": [
        "# Step 9: Convert an image to grayscale\n",
        "Often in machine learning, a full color image isn't necessary. If we can simplify the data, we can make our models faster and simpler, and converting to grayscale is one good way to do that.\n",
        "\n",
        "To convert to grayscale, we need to use the built-in OpenCV method for converting colors, `cv2.cvtColor()`. We used it once in the \"Display an image\" section of this notebook. With that as a reference, plus the help of Google, can you convert the below image to grayscale?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruf-t_ut6z2S"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "dog = cv2.imread(\"dog.jpeg\")\n",
        "gray_dog = # ????\n",
        "\n",
        "show(dog, gray_dog)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVPB-B5s72oL"
      },
      "source": [
        "**Challenge question:** Change the code to print out `dog.shape` and `gray_dog.shape`. Why are they different?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX_hV3tE8xYB"
      },
      "source": [
        "# Step 10: Resize & stretch an image\n",
        "The `cv2.resize` method distorts an image to be a particular width/height.\n",
        "\n",
        "With the help of Google, can you distort the polar bear image below to be very short and wide?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoD2sGNe8zdy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "polarbear = cv2.imread(\"polarbear.jpeg\")\n",
        "stretched = # ?????\n",
        "\n",
        "show(polarbear, stretched)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsFF4-Mt9h0g"
      },
      "source": [
        "# Step 11: Crop an image\n",
        "Since our images are just numpy arrays (i.e. big blocks of numbers), we can use python's `[]` indexing to crop our image.\n",
        "\n",
        "**Question:** Can you change the following code to crop to just the yellow part of the pineapple? (Use the labelled axes on the image output to know which numbers to choose.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-WcIHse97LH"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "pineapple = cv2.imread(\"pineapple.jpeg\")\n",
        "\n",
        "# Crop the image using [start_row:end_row , start_col:end_col] syntax\n",
        "cropped = pineapple[500:1500, 500:1000]\n",
        "\n",
        "show(pineapple, cropped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhbAXJKi-2SY"
      },
      "source": [
        "# Step 12: Edge detection\n",
        "Sometimes in machine learning, it can be useful to detect where the edges are in an image. OpenCV has this feature built-in. There are many different edge-detection algorithms you can use, but we'll try Canny edge detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hulHtt7_N16"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "pineapple = cv2.imread(\"pineapple.jpeg\")\n",
        "\n",
        "edges = cv2.Canny(pineapple,100,200)\n",
        "\n",
        "show(pineapple, edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R66Oyo7nk3Vx"
      },
      "source": [
        "# Step 13: Image distortion with `remap`\n",
        "Here's a fun one. You know those silly mirrors you sometimes see that stretch out the image to make it look all wonky? We can do that with OpenCV too. Unfortunately, doing so requires a bit of setup, so we're going to quickly define a helper function to make it easier. ([Learn more](https://msu-ai.notion.site/Workshop-Instructions-71ae82f6d8d9452586e6626ffb48e1b9#8ceac9b4328548eb80227c0b6ef500b9)) Just run this once; it won't do anything interesting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buzlbB0CysaA"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def distort(img, get_src_pos):\n",
        "  height, width = img.shape[:2]\n",
        "\n",
        "  get_x = lambda y, x: get_src_pos(x, y, width, height)[0]\n",
        "  get_y = lambda y, x: get_src_pos(x, y, width, height)[1]\n",
        "\n",
        "  map_x = np.fromfunction(get_x, img.shape[:2], dtype=np.float32)\n",
        "  map_y = np.fromfunction(get_y, img.shape[:2], dtype=np.float32)\n",
        "\n",
        "  return cv2.remap(img, map_x, map_y, cv2.INTER_LINEAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33DMv5D9yydu"
      },
      "source": [
        "Now the fun part. We get to define our own function that tells each point of the image how it should move around. Let's try a simple one, where we double each x and y coordinate, and then view the distorted image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzXxrH442u-H"
      },
      "outputs": [],
      "source": [
        "def get_src_pos(x, y, width, height):\n",
        "  return (width-x, height-y)\n",
        "\n",
        "image = cv2.imread(\"cat.jpeg\")\n",
        "distorted = distort(image, get_src_pos)\n",
        "\n",
        "show(image, distorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tthB881TvrUi"
      },
      "source": [
        "Hmmm... This is cool, but it's a little counter-intuitive. We doubled the coordinates, but it caused the image to shrink! (I expected it to grow.)\n",
        "\n",
        "Here's why: The way remap works is **not** by taking each point in the old image and using our function to move it to a new point. Instead, it takes each point in the *new* image and uses our function to find which point in the *old* image it corresponds to. In short, everything is going to be the reverse of your intuition. ([Learn more](https://msu-ai.notion.site/Workshop-Instructions-71ae82f6d8d9452586e6626ffb48e1b9#45003339d84e4b2396719479e54e891a))\n",
        "\n",
        "---\n",
        "\n",
        "Let's try another distortion. This time we will translate the image by adding to its x and y coordinates. Again, the transformation sort of seems reversed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z74nVO2k4SXS"
      },
      "outputs": [],
      "source": [
        "def get_src_pos(x, y, width, height):\n",
        "  return (x + 500, y + 200)\n",
        "\n",
        "image = cv2.imread(\"cat.jpeg\")\n",
        "distorted = distort(image, get_src_pos)\n",
        "\n",
        "show(image, distorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsxAaPaUSrS-"
      },
      "source": [
        "Now's a good time for you to edit the transformation yourself and try to make something cool.\n",
        "\n",
        "**Question:** Can you flip the image horizontally? (**Hint:** you might need to use the image `width`.)\n",
        "\n",
        "**Question:** Can you rotate the image by 180 degrees? (**Hint:** Two reflections make a rotation.)\n",
        "\n",
        "---\n",
        "\n",
        "If you're feeling crazy, you can also use more interesting functions (like your usual trig operations) to make your images more interesting.\n",
        "- `np.sin(x)`\n",
        "- `np.cos(x)`\n",
        "- `np.tan(x)`\n",
        "\n",
        "One word of warning: The usual math functions, like `math.sin(x)`, will not work. The `x` and `y` being passed to your `get_src_pos` function are *not* numbers. For efficiency, they are entire numpy arrays full of numbers, so that your function can effectively perform many calculations at once. Usually this won't affect the way you write code, but it *does* mean you need to use the numpy-specific versions of the math functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zjFeMiOY7xL"
      },
      "outputs": [],
      "source": [
        "def get_src_pos(x, y, width, height):\n",
        "  return (x + np.sin(y / 200) * 300, y)\n",
        "\n",
        "image = cv2.imread(\"cat.jpeg\")\n",
        "distorted = distort(image, get_src_pos)\n",
        "\n",
        "show(image, distorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkzP8S8R4Y8P"
      },
      "source": [
        "As you can see, you can get some pretty crazy results. Try writing your own transformation function to design something cool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VynLFlVtvf6O"
      },
      "source": [
        "# Step 14: Webcam filter contest 📸\n",
        "With many new tools in your toolbelt, it's finally time to put them all together. Your job is to combine many OpenCV operations to create a cool image filter. It can be fun, funny, or seriously cool. This is your chance to get creative.\n",
        "\n",
        "Before getting started, please run the following block of code. It sets up a function that makes it easy to take photos with your webcam. You do not need to understand or edit this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5eLGaXxvuvb"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def take_photo():\n",
        "  display(Javascript('''\n",
        "    async function takePhoto(quality = 0.8) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "  '''))\n",
        "\n",
        "  try:\n",
        "    data = eval_js('takePhoto()')\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    arr = np.frombuffer(binary, np.uint8)\n",
        "    image = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
        "    return image\n",
        "  except Exception as err:\n",
        "    # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "    # grant the page permission to access it.\n",
        "    print(str(err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qej_pmNQyJQZ"
      },
      "source": [
        "Awesome! With that out of the way, you're ready to begin designing.\n",
        "\n",
        "The following block of code contains a `filter` function that transforms an image. Your job is to edit the `filter` function to create a cool design. When you run the code, you'll be prompted to take a photo with the webcam and then you'll see the result of your filter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kaJCIJqTKmU"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Define your own filter here!\n",
        "def filter(img):\n",
        "  # Invert the photo\n",
        "  img = cv2.bitwise_not(img)\n",
        "\n",
        "  # Draw a red circle\n",
        "  cv2.circle(img, center=(100, 100), radius=50, color=(0, 0, 255), thickness=-1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# Take a photo from the webcam\n",
        "img = take_photo()\n",
        "\n",
        "# Apply your custom filter\n",
        "filtered = filter(img)\n",
        "\n",
        "# Display the comparison and save the filtered version to my-filtered-photo.jpeg\n",
        "show(img, filtered)\n",
        "cv2.imwrite(\"my-filtered-photo.jpeg\", filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGO31HJ_y29p"
      },
      "source": [
        "**When you've created a filter you're happy with, download the image and submit it in the #chat channel on Discord!** ([Learn more](https://msu-ai.notion.site/Workshop-Instructions-71ae82f6d8d9452586e6626ffb48e1b9#aeca0f16925e450fa072f6215c6f388e))\n",
        "* Your filtered photo is automatically saved in the files tab on the left as `my-filtered-photo.jpeg`. Use the three dot menu to download it to your computer.\n",
        "\n",
        "Feel free to submit multiple different filters if you're feeling extra creative. ;)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "OpenCV Workshop",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
